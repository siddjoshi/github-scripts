import argparse
import json
import os
import subprocess
import tempfile
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Tuple

import yaml
from github import Github
from github.Issue import Issue

from change_detector import has_repo_changed
from parallel_scanner import run_in_parallel
from state_manager import ScanState


def load_config(path: str) -> Dict[str, Any]:
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def get_github_client(token: str, base_url: Optional[str] = None) -> Github:
    if base_url:
        return Github(base_url=base_url, login_or_token=token)
    return Github(login_or_token=token)


def list_repositories(client: Github, scope_type: str, scope_name: str) -> List[str]:
    repos: List[str] = []
    if scope_type == "organization":
        org = client.get_organization(scope_name)
        repos = [repo.full_name for repo in org.get_repos()]
    elif scope_type == "enterprise":
        # The enterprise repos API is not covered by PyGithub helpers; use raw request
        url = f"/enterprises/{scope_name}/repos"
        page = 1
        while True:
            _, data = client._Github__requester.requestJsonAndCheck(  # type: ignore[attr-defined]
                "GET", url, parameters={"per_page": 100, "page": page}
            )
            if not data:
                break
            repos.extend([r["full_name"] for r in data])
            if len(data) < 100:
                break
            page += 1
    else:
        raise ValueError("scope_type must be 'enterprise' or 'organization'")
    return repos


def build_tool_command(
    repo: str, config: Dict[str, Any], output_file: str, token: str, base_url: Optional[str]
) -> List[str]:
    scan_settings = config.get("scan_settings", {})
    cmd = [
        "npx",
        "github-sbom-toolkit",
        "--repo",
        repo,
        "--sbom-cache",
        scan_settings.get("sbom_cache_dir", "./malware-scanning/sbom-cache"),
        "--malware-cache",
        scan_settings.get("malware_cache_dir", "./malware-scanning/malware-cache"),
        "--json",
        "--output-file",
        output_file,
    ]

    if scan_settings.get("sync_sboms", True):
        cmd.append("--sync-sboms")
    if scan_settings.get("match_malware", True):
        cmd.append("--match-malware")
    if scan_settings.get("sync_malware", True):
        cmd.append("--sync-malware")

    if scan_settings.get("concurrency"):
        cmd.extend(["--concurrency", str(scan_settings["concurrency"])])
    if scan_settings.get("sbom_delay_ms"):
        cmd.extend(["--sbom-delay", str(scan_settings["sbom_delay_ms"])])
    if scan_settings.get("light_delay_ms"):
        cmd.extend(["--light-delay", str(scan_settings["light_delay_ms"])])

    extra_purls = scan_settings.get("extra_purls") or []
    for purl in extra_purls:
        cmd.extend(["--purl", purl])

    if base_url:
        cmd.extend(["--base-url", base_url])

    env = os.environ.copy()
    env["GITHUB_TOKEN"] = token
    return cmd, env


def run_tool_for_repo(
    repo: str,
    config: Dict[str, Any],
    token: str,
    base_url: Optional[str],
) -> Tuple[str, Dict[str, Any]]:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".json") as tmp:
        output_file = tmp.name

    cmd, env = build_tool_command(repo, config, output_file, token, base_url)
    try:
        subprocess.run(cmd, check=True, env=env, capture_output=True, text=True)
        with open(output_file, "r", encoding="utf-8") as f:
            data = json.load(f)
    except subprocess.CalledProcessError as exc:
        return repo, {"error": exc.stderr or str(exc)}
    except FileNotFoundError:
        return repo, {"error": "github-sbom-toolkit output not found"}
    finally:
        try:
            os.unlink(output_file)
        except OSError:
            pass

    return repo, data


def format_mentions(notifications: Dict[str, Any]) -> str:
    users = notifications.get("users") or []
    teams = notifications.get("teams") or []
    mentions = []
    mentions.extend([f"@{u}" for u in users])
    mentions.extend([f"@{t}" for t in teams])
    return " ".join(mentions)


def build_issue_body(repo: str, findings: List[Dict[str, Any]], mentions: str) -> str:
    lines = [f"Malware matches detected for `{repo}`.", ""]
    lines.append("| Package | Version | PURL | Advisory |")
    lines.append("| --- | --- | --- | --- |")
    for f in findings:
        pkg = f.get("package", "")
        version = f.get("version", "")
        purl = f.get("purl", "")
        advisory = f.get("advisory", {}).get("ghsaId") or f.get("advisory", {}).get("id", "")
        advisory_url = f.get("advisory", {}).get("url") or ""
        advisory_cell = f"[{advisory}]({advisory_url})" if advisory_url else advisory
        lines.append(f"| `{pkg}` | `{version}` | `{purl}` | {advisory_cell} |")

    lines.append("")
    if mentions:
        lines.append(f"Notifying: {mentions}")
        lines.append("")
    lines.append(f"_Scan time: {datetime.now(timezone.utc).isoformat()}_")
    return "\n".join(lines)


def upsert_issue(
    gh: Github,
    central_repo: str,
    repo_name: str,
    findings: List[Dict[str, Any]],
    labels: List[str],
    issue_options: Dict[str, Any],
    mentions: str,
):
    repo = gh.get_repo(central_repo)
    title = f"[Malware Alert] Repository: {repo_name} - {len(findings)} malware package(s) found"

    existing: Optional[Issue] = None
    for issue in repo.get_issues(state="open"):
        if issue.title == title:
            existing = issue
            break

    if not findings:
        if existing and issue_options.get("close_when_resolved", True):
            existing.create_comment("No malware findings in the latest scan. Closing.")
            existing.edit(state="closed")
        return

    body = build_issue_body(repo_name, findings, mentions)
    if existing:
        existing.edit(body=body)
    else:
        repo.create_issue(title=title, body=body, labels=labels)


def group_findings(raw_result: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Normalize github-sbom-toolkit JSON output into a list of findings with keys:
    package, version, purl, advisory{ghsaId,id,url}
    """
    findings: List[Dict[str, Any]] = []
    packages = raw_result.get("packages") or raw_result.get("matches") or []
    for entry in packages:
        pkg = entry.get("package") or entry.get("name") or ""
        version = entry.get("version") or ""
        purl = entry.get("purl") or ""
        advisory = entry.get("advisory") or {}
        findings.append(
            {
                "package": pkg,
                "version": version,
                "purl": purl,
                "advisory": advisory,
            }
        )
    return findings


def scan_repo_worker(
    repo: str,
    client: Github,
    config: Dict[str, Any],
    token: str,
    base_url: Optional[str],
    state: ScanState,
) -> Tuple[str, Dict[str, Any]]:
    incremental = config.get("performance", {}).get("incremental_scan", True)
    last_scan_time = state.get_last_scan_time(repo) if incremental else None

    changed, latest_sha = has_repo_changed(client, repo, last_scan_time)
    if incremental and not changed:
        return repo, {"skipped": True, "reason": "unchanged"}

    repo_name = repo.split("/")[-1]
    repo_result = {"findings": []}  # default shape

    repo_id, raw_result = run_tool_for_repo(repo, config, token, base_url)
    if raw_result.get("error"):
        return repo, {"error": raw_result["error"]}

    findings = group_findings(raw_result)
    repo_result["findings"] = findings
    repo_result["latest_commit"] = latest_sha
    repo_result["scan_time"] = datetime.now(timezone.utc).isoformat()
    return repo, repo_result


def main() -> None:
    parser = argparse.ArgumentParser(description="Enterprise malware scanner wrapper.")
    parser.add_argument("--config", default="./malware-scanning/config.yaml", help="Path to config file.")
    parser.add_argument("--scope-type", choices=["enterprise", "organization"], help="Override scope type.")
    parser.add_argument("--scope-name", help="Override scope name.")
    parser.add_argument("--output-dir", default="./malware-scanning/run-logs", help="Directory for results.")
    parser.add_argument("--debug", action="store_true", help="Enable debug logging.")
    args = parser.parse_args()

    token = os.getenv("GITHUB_TOKEN")
    if not token:
        raise SystemExit("GITHUB_TOKEN is required")

    if not os.path.exists(args.config):
        raise SystemExit(f"Config file not found: {args.config}")

    config = load_config(args.config)
    scope_type = args.scope_type or config.get("scope", {}).get("type")
    scope_name = args.scope_name or config.get("scope", {}).get("name")
    base_url = os.getenv("GITHUB_API_URL")

    if not scope_type or not scope_name:
        raise SystemExit("Scope type and name are required (enterprise/org).")

    gh = get_github_client(token, base_url)

    central_repo_cfg = config.get("central_repo", {})
    central_repo_full = f"{central_repo_cfg.get('owner')}/{central_repo_cfg.get('name')}"
    labels = config.get("issue_labels", [])
    issue_options = config.get("issue_options", {})
    mentions = format_mentions(config.get("notifications", {}))

    performance_cfg = config.get("performance", {})
    max_workers = performance_cfg.get("max_workers", 10)

    state_path = performance_cfg.get("state_db_path") or None
    state = ScanState(path=state_path)

    repos = list_repositories(gh, scope_type, scope_name)

    def worker(repo_name: str) -> Tuple[str, Dict[str, Any]]:
        return scan_repo_worker(repo_name, gh, config, token, base_url, state)

    results = run_in_parallel(repos, worker, max_workers=max_workers)

    os.makedirs(args.output_dir, exist_ok=True)
    summary_path = os.path.join(
        args.output_dir,
        f"malware-scan-summary-{datetime.now(timezone.utc).strftime('%Y%m%dT%H%M%SZ')}.json",
    )
    summary: Dict[str, Any] = {"results": {}, "errors": {}}

    for repo_name, data in results:
        if data.get("error"):
            summary["errors"][repo_name] = data["error"]
            continue
        if data.get("skipped"):
            summary["results"][repo_name] = {"skipped": True, "reason": data.get("reason")}
            continue

        findings = data.get("findings", [])
        summary["results"][repo_name] = {
            "findings": findings,
            "scan_time": data.get("scan_time"),
            "latest_commit": data.get("latest_commit"),
        }

        # Update state
        scan_time = datetime.fromisoformat(data["scan_time"])
        state.update_repo_state(repo_name, scan_time, data.get("latest_commit"), findings)

        # Issue handling
        upsert_issue(
            gh=gh,
            central_repo=central_repo_full,
            repo_name=repo_name,
            findings=findings,
            labels=labels,
            issue_options=issue_options,
            mentions=mentions,
        )

    with open(summary_path, "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2)

    state.save()


if __name__ == "__main__":
    main()

